{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch import nn, optim\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "X = torch.tensor(np.arange(0, 31), dtype=torch.float32).view(-1, 1)\n",
    "Y = torch.tensor(np.array([30, 35, 33, 32, 34, 37, 39, 38, 36, 36, 37, 39, 42, 45, 45, 41, 40, 39, 42, 44, 47, 49, 50, 49, 46, 48, 50, 53, 55, 54, 53]), dtype=torch.float32).view(-1, 1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(1, 32)\n",
    "        self.layer2 = nn.Linear(32, 64)\n",
    "        self.layer3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def train_and_test_nn(train_indices, test_indices, epochs):\n",
    "    model = NeuralNetwork()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    train_X = X[train_indices]\n",
    "    train_Y = Y[train_indices]\n",
    "    test_X = X[test_indices]\n",
    "    test_Y = Y[test_indices]\n",
    "\n",
    "    num_epochs = epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_X)\n",
    "        loss = criterion(output, train_Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    preds_train = model(train_X)\n",
    "    train_loss = criterion(preds_train, train_Y)\n",
    "\n",
    "    preds_test = model(test_X)\n",
    "    test_loss = criterion(preds_test, test_Y)\n",
    "    return train_loss, test_loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case (ii): First 20 points as training data\n",
      "\n",
      "Train Error: 4.439381122589111\n",
      "Test Error: 9.366402626037598\n",
      "\n",
      "Case (iii): First 10 and last 10 points as training data\n",
      "\n",
      "Train Error: 3.2382946014404297\n",
      "Test Error: 7.333491802215576\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Case (ii): First 20 points as training data\")\n",
    "train_error, test_error = train_and_test_nn(np.arange(20), np.arange(20, 30), 1000)\n",
    "print(f\"\\nTrain Error: {train_error}\\nTest Error: {test_error}\")\n",
    "\n",
    "print(\"\\nCase (iii): First 10 and last 10 points as training data\")\n",
    "train_error2, test_error2 = train_and_test_nn(np.hstack([np.arange(10), np.arange(21, 31)]), np.arange(10, 21), 1000)\n",
    "print(f\"\\nTrain Error: {train_error2}\\nTest Error: {test_error2}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "#HW 1 Scores:\n",
    "#1\n",
    "# Error for Line (Train): 2.242749386808538\n",
    "# Error for Parabola (Train): 2.1255393482773766\n",
    "# Error for Polynomial (Train): 0.028351503968806435\n",
    "# Error for Line (Test): 3.36363873604787\n",
    "# Error for Parabola (Test): 8.713651781874919\n",
    "# Error for Polynomial (Test): 28617752784.428474\n",
    "\n",
    "#2\n",
    "# Error for Line (Train): 1.851669904329375\n",
    "# Error for Parabola (Train): 1.8508364115957907\n",
    "# Error for Polynomial (Train): 0.1638133765080727\n",
    "# Error for Line (Test): 2.8065076975181618\n",
    "# Error for Parabola (Test): 2.774982896893291\n",
    "# Error for Polynomial (Test): 483.9099124568562"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 PCA Modes:\n",
      "[[ 6.03863025e-18 -2.06760528e-18 -1.97133939e-19 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 9.83706835e-17 -1.17227770e-17 -9.03127920e-18 ... -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00]\n",
      " [ 4.07530131e-17 -3.40610710e-17  6.00320808e-18 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " ...\n",
      " [ 4.77907602e-17  8.45964747e-18  1.45399137e-17 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-3.93112540e-17  5.12008009e-17 -9.54434652e-17 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 5.45389222e-18 -5.40219756e-17  6.81901851e-17 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]]\n",
      "Epoch [1/10], Loss: 0.2357\n",
      "Epoch [2/10], Loss: 0.1875\n",
      "Epoch [3/10], Loss: 0.1504\n",
      "Epoch [4/10], Loss: 0.1409\n",
      "Epoch [5/10], Loss: 0.2250\n",
      "Epoch [6/10], Loss: 0.0334\n",
      "Epoch [7/10], Loss: 0.1476\n",
      "Epoch [8/10], Loss: 0.0308\n",
      "Epoch [9/10], Loss: 0.0669\n",
      "Epoch [10/10], Loss: 0.0460\n",
      "Accuracy of the network on the 10000 test images: 96.78\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# Load the MNIST train and test datasets\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "train_dataset = torchvision.datasets.MNIST('~/.torch/datasets', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST('~/.torch/datasets', train=False, download=True, transform=transform)\n",
    "\n",
    "# Compute the first 20 PCA modes of the digit images\n",
    "train_data = train_dataset.data.numpy().reshape(-1, 28*28)\n",
    "pca = PCA(n_components=20)\n",
    "pca.fit(train_data)\n",
    "print(f'First 20 PCA Modes:\\n{pca.components_}')\n",
    "\n",
    "# Loaders for the train and test datasets\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000)\n",
    "\n",
    "# Define the neural network\n",
    "class FeedForwardNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(28 * 28, 256)\n",
    "        self.fc2 = torch.nn.Linear(256, 128)\n",
    "        self.fc3 = torch.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = FeedForwardNN()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the neural network\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # Reshape the data and perform the forward pass\n",
    "        data = data.view(data.size(0), -1)\n",
    "        predictions = model(data)\n",
    "\n",
    "        # Compute the loss, gradients, and update the parameters\n",
    "        loss = criterion(predictions, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print the loss for the current epoch\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Test the neural network\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data, targets in test_loader:\n",
    "        # Reshape the data and perform the forward pass\n",
    "        data = data.view(data.size(0), -1)\n",
    "        predictions = model(data)\n",
    "\n",
    "        # Compute the number of correct predictions\n",
    "        _, predicted = torch.max(predictions.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#HW3 Scores:\n",
    "#Tree: 0.8769\n",
    "#SVM: 0.9792\n",
    "#LDA: 0.8730\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#SVM LDA and Decision Trees\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(60000, 784).T\n",
    "X_test = X_test.reshape(10000, 784).T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8769\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(random_state=44)\n",
    "tree.fit(X_train.T, y_train)\n",
    "y_pred_tree = tree.predict(X_test.T)\n",
    "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
    "print(accuracy_tree)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9792\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(probability=False)\n",
    "svm.fit(X_train.T, y_train)\n",
    "y_pred_svm = svm.predict(X_test.T)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(accuracy_svm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.873\n"
     ]
    }
   ],
   "source": [
    "lda = LDA()\n",
    "lda.fit(X_train.T, y_train)\n",
    "y_pred_lda = lda.predict(X_test.T)\n",
    "accuracy_lda = accuracy_score(y_test, y_pred_lda)\n",
    "print(accuracy_lda)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}